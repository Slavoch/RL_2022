{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c715e6",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#333333; text-align:center; line-height: 0;\"> <img style=\"right;\" src=\"logo.png\" width=18% height=18%> Reinforcement Learning | Assignment 2 \n",
    "</h1>\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "The goal of this assignment is to implement:\n",
    "- system \n",
    "- conditional model \n",
    "- actor \n",
    "- critic\n",
    "- REINFORCE\n",
    "\n",
    "___Total points:___ 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96415eab",
   "metadata": {},
   "source": [
    "###  <font color=\"blue\"> A brief introduction </font>\n",
    "Examine it carefully, it covers most of your possible needs to make an assignment.\n",
    "\n",
    "***\n",
    "\n",
    "### About Rcognita\n",
    "The platform for this (and all subsequent work) is [Rcognita](https://gitflic.ru/project/aidynamicaction/rcognita), a framework for applying control theory and machine learning algorithms to control problems, an integral part of which is the closed-loop interaction between the agent under control and the environment evolving over time. In the Rcognita paradigm, the main bearer of all the classes and variables needed to run the simulation is the `pipeline`. \n",
    "\n",
    "The main parts of `pipeline` are: \n",
    "* `simulator`, which is defined at module `simulators.py` and responsible for simulation of evolution of the environment\n",
    "* `actor`, defined at module `actors.py`, which is responsible for obtaining of action\n",
    "* `critic`, defined at module `critics.py`, which is reponsible for learning of reward function and obtaining its value \n",
    "* `controller`, which is defined at module `controllers.py` and it's needed to put it all together into an RL (or other) controller\n",
    "* `system`, which is defined at module `systems.py`.\n",
    "\n",
    "Other minor things are also declarated in the pipeline and assembled module by module up to the execution of the pipeline itself. \n",
    "Just to be on the same page, we provide some notation to prevent further confusions.\n",
    "* `weights` is the general name and for weights of neural network and for values in tables of value function and policy as well. This agreement comes from the motivation for being consistent with classical RL where critic and actor are being implemented as some neural networks with some **weights**. So, here comes the second term\n",
    "* `model`. It's obvious that parameters give specificity to something. But the general form itself is being called `model`. There are plenty of models of different types and forms (such as NN). Model is what critic and actor and even running cost always have, no matter what.\n",
    "* `predictor` - Inspite of it's cryptic name, this object performs an important function, namely, it carries the law by which the dynamics of our system is being predicted in future. For example, if we have some differential equation\n",
    "$\n",
    "\\begin{cases}\n",
    "\\dot{\\boldsymbol x} = \\boldsymbol f(\\boldsymbol x, \\boldsymbol u)\\\\\n",
    "\\boldsymbol y = h(\\boldsymbol x) \\\\\n",
    "\\boldsymbol x(0)=\\boldsymbol x_{0}\\\\\n",
    "\\end{cases}\n",
    "$\n",
    "where $x_{0}$ is the **initial state**.\n",
    "in general, there are several ways of prediction: \n",
    "> - **Analytical**, when we have a precise formula of analytical solution $\\boldsymbol x(t)$ to the ODE and have no problems to compute it at any given time. This is great but not that possible in real life. Nevertheless, our predictor could be expressed like:  $\\text{predictor}(\\boldsymbol x(\\tau),dt) = \\boldsymbol x(\\tau + dt)$\n",
    "> - **Numerical** way is mostly a case. The simplest way of prediction then is an Euler method:\n",
    "$\\boldsymbol x_{k+1}= \\text{predictor}(\\boldsymbol x_k, \\delta)=\\boldsymbol x_{k}+\\delta \\boldsymbol f\\left(\\boldsymbol x_{k}, \\boldsymbol u_{k}\\right) \\text {, }$\n",
    "\n",
    "In this assignment we meet a new object - **scenario**. Scenario is a module that forms and executes the main loops for different scenarios, like online or episodical scenario. In this assignment we will use an episodical scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bd659",
   "metadata": {},
   "source": [
    "<a id='Notation'></a>\n",
    "### Notation summary\n",
    "From now and on we will use the following notation:\n",
    "\n",
    "| Notation &nbsp; &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp;&nbsp;Description |\n",
    "|:-----------------------:|-------------|\n",
    "| $\\boldsymbol f(\\cdot, \\cdot, \\cdot) : \\mathbb{R}^{n+1}\\times \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ |A **state dynamic function** or, more informally, **righ-hand-side** of a system <br /> of ordinary differential equations $\\dot{\\boldsymbol x} = \\boldsymbol f(t, \\boldsymbol x, \\boldsymbol u)$|\n",
    "| $\\boldsymbol x \\in \\mathbb{R}^{n} $ | An element of the **state space** of a controlled system of dimensionality $n$ |\n",
    "| $\\boldsymbol u \\in \\mathbb{R}^{m}$ | An element of the **action space** of a controlled system of dimensionality $m$ |\n",
    "| $\\boldsymbol y \\in \\mathbb{R}^{k}$ | An **observartion**|\n",
    "| $\\mathbb{X}\\subset \\mathbb{R}^{n} $| **State constraint set**|\n",
    "| $\\mathbb{U}\\subset \\mathbb{R}^{m} $| **Action constraint set**|\n",
    "| $\\boldsymbol h(\\cdot): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{k}$ | **Observation function**  |\n",
    "| $\\boldsymbol\\rho(\\cdot) : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}$ | **Policy** function |\n",
    "| $r(\\cdot) : \\mathbb{R}^n \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}$ | **Running cost** function  |\n",
    "\n",
    "\n",
    "### Goal\n",
    "Our main goal here is to implement the whole system almost from scratch and to apply Policy Gradient algorithm to [PID-regulator](https://en.wikipedia.org/wiki/PID_controller) coefficients (more precisely, P and D coefficient) tuning\n",
    "\n",
    "###  <font color=\"blue\"> Algorithm description </font>\n",
    "\n",
    "I. **Initialization**:\n",
    "- set iterations number **N_iterations**\n",
    "- set episodes number **N_episodes**\n",
    "- set **discount factor** $\\gamma$\n",
    "- initialize some **policy** parameters $\\theta_0$, learning rate $\\eta$\n",
    "\n",
    "II. **Main loop**:<br/>\n",
    "(Run episodical scenario)\n",
    ">**for** i in range(**N_iterations**):\n",
    ">>**for** j in range(**N_episodes**):\n",
    ">>> **while** **time** < **t1**:\n",
    "(corresponding utilized parts of Rcognita are provided in bold inside parentheses)\n",
    ">>>> - simulate environment evolution (**simulator**, **system**)\n",
    ">>>> - obtain observation (**system**) $\\boldsymbol y_i = \\boldsymbol h(\\boldsymbol x_i)$\n",
    ">>>> - obtain action (**actor**) $u_i \\sim  \\mathcal{N}(\\mu,\\,\\sigma^{2})$\n",
    ">>>> - compute and store new gradient (**actor.model**)\n",
    ">>>> - update accumulated outcome (**critic**): $\\sum_{i=0}^N \\gamma^i \\cdot\\left(y_i, u_i\\right)$\n",
    ">>> - compute and store REINFORCE objective gradient (**scenario**): $\\sum_{k=0}^N \\nabla_\\theta \\ln \\rho^\\theta(u_k \\vert y_k) \\cdot \\sum_{i=0}^N \\gamma^i \\cdot\\left(y_i, u_i\\right)$\n",
    ">> - compute mean overall stored REINFORCE objective gradients (**scenario**): $\\mathbb{E}\\left[\\sum_{k=0}^N \\nabla_\\theta \\ln \\rho^\\theta(u_k \\vert y_k) \\cdot \\sum_{i=0}^N \\gamma^i \\cdot\\left(y_i, u_i\\right)\\right]$\n",
    ">> - perform a gradient step (**scenario**): $\\theta_{i+1}=\\theta_i+\\eta \\mathbb{E}\\left[\\sum_{k=0}^N \\nabla_\\theta \\ln \\rho^\\theta(u_k \\vert y_k) \\cdot \\sum_{i=0}^N \\gamma^i \\cdot\\left(y_i, u_i\\right)\\right]$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"\n",
    "Just importing all the necessary stuff here.\n",
    "DO NOT CHANGE\n",
    "\"\"\"\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rcognita_framework.pipelines.pipeline_inverted_pendulum import PipelineInvertedPendulum\n",
    "from rcognita_framework.rcognita.actors import ActorProbabilisticEpisodic\n",
    "from rcognita_framework.rcognita.critics import CriticTrivial\n",
    "from rcognita_framework.rcognita.systems import SysInvertedPendulum\n",
    "from rcognita_framework.rcognita.models import ModelGaussianConditional\n",
    "from rcognita_framework.rcognita.scenarios import EpisodicScenario\n",
    "from rcognita_framework.rcognita.utilities import rc\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039587ee",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 1: System implementation </h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903acd6",
   "metadata": {},
   "source": [
    "<img style=\"left;\" src=\"n_pendulum.png\" width=18% height=18%>\n",
    "in our case the system has the following view\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\dot{\\varphi} = \\theta \\\\\n",
    "\\dot{\\theta} = \\frac{g}{l}\\sin{\\varphi} + \\frac{u}{ml^2} \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Your task is to implement this system. More precisely, there are two crucial methods: \n",
    "* `_compute_state_dynamics(self, time, state, action, disturb)` - which computes and returns the $\\boldsymbol f(t, \\boldsymbol x, \\boldsymbol u)$ - the right-hand-side of the system. (You should fill the `Dstate` with correct values $(\\boldsymbol \\varphi, \\dot{\\boldsymbol \\varphi})$)\n",
    "* `out(state, time, action)`- which yields us an observation $\\boldsymbol y = \\boldsymbol h(\\boldsymbol x)$, where $\\boldsymbol y = (\\varphi, \\int\\limits_0^t \\varphi dt, \\dot{\\varphi})$.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509cbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SysInvertedPendulumStudent(SysInvertedPendulum):\n",
    "    \"\"\"\n",
    "    System class: mathematical inverted pendulum\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _compute_state_dynamics(self, time, state, action, disturb=[]):\n",
    "        \"\"\"\n",
    "        Method computes state dynamics function of the system\n",
    "        \"\"\"\n",
    "\n",
    "        m, g, l = self.pars[0], self.pars[1], self.pars[2]\n",
    "\n",
    "        Dstate = ...\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "\n",
    "        return Dstate\n",
    "\n",
    "    def out(self, state, time=None, action=None):\n",
    "        \"\"\"\n",
    "        Method computes observation\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26479e3a",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 2: Conditional model implementation</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc99856",
   "metadata": {},
   "source": [
    "In our setting we have a stochastic policy wich is modeled by a conditional distribution $\\rho^w(u | \\boldsymbol y) = \\frac{1}{\\sqrt{\\pi}}\\exp{-\\frac{(u-\\mu)^2}{0.5}}$,\n",
    "where $\\boldsymbol w:=(w_1, 0, w_2)$, $\\mu:=-\\langle \\boldsymbol w,\\boldsymbol y\\rangle$\n",
    "\n",
    "Implement the following methods:\n",
    "* `update_expectation(self, arg_condition)` - it should compute the expectation parameter of the distribution given the passed `arg_condition` \n",
    "* `compute_gradient(self, argin)`- self-explanatory :) Compute it yourself on the paper first.\n",
    "* `update(self)` - this method is being invoked after each gradient update. So it just basically resets the model. Note that you can access to `self.arg_condition_init` for these purposes\n",
    "\n",
    "***\n",
    "\n",
    "`arg_condition` in this setting is a s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGaussianConditionalStudent(ModelGaussianConditional):\n",
    "\n",
    "    model_name = \"model-gaussian\"\n",
    "\n",
    "    def update_expectation(self, arg_condition):\n",
    "        \"\"\"\n",
    "        update expectation based on arg_condition\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "        \n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "\n",
    "    def compute_gradient(self, argin):\n",
    "        \"\"\"\n",
    "        Compute grad manually\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "\n",
    "    def update(self, new_weights):\n",
    "        \"\"\"\n",
    "        transform the new_weights into expectation \n",
    "        and apply update_expectation method\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "\n",
    "    def sample_from_distribution(self, argin):\n",
    "        self.update_expectation(argin)\n",
    "        self.update_covariance()\n",
    "    \n",
    "        return np.array([\"\"\"here should be a normally distributed random variable \n",
    "                                            N(self.expectation, self.covariance)\"\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70696b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 3: Actor implementation</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf68765",
   "metadata": {},
   "source": [
    "As you remember from the introduction, actor is responsible for the action obtaining. During the episode simulation it samples action according to it's model. By default, `update(self, observation)` method performs this operation.\n",
    "But indeed we also should clip the action obtained from distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorProbabilisticEpisodicStudent(ActorProbabilisticEpisodic):\n",
    "\n",
    "    def update(self, observation):\n",
    "        \"\"\"\n",
    "        obtain and store the action\n",
    "        \"\"\"\n",
    "        action_sample = ### use here sample_from_distribution from model\n",
    "        self.action = np.array(\n",
    "            np.clip(action_sample, self.action_bounds[0], self.action_bounds[1])\n",
    "        )\n",
    "        self.action_old = self.action\n",
    "        current_gradient = ### compute gradient here using the corresponding model's method you've just implemented\n",
    "        self.store_gradient(current_gradient)\n",
    "\n",
    "    def update_weights_by_gradient(self, gradient, learning_rate):\n",
    "        \"\"\"\n",
    "        Perform a step towards the gradient with some learning rate\n",
    "        \"\"\"\n",
    "        model_weights = self.model.weights\n",
    "        new_model_weights = ### A gradient step should be performed here\n",
    "\n",
    "        self.model.update(new_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e9ed80",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 4: Critic implementation</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f08857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticTrivialStudent(CriticTrivial):\n",
    "    \"\"\"\n",
    "    This is a dummy to calculate outcome (accumulated running objective).\n",
    "    Use an Euler method for that\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, running_objective, sampling_time=0.01):\n",
    "        self.running_objective = running_objective\n",
    "        self.sampling_time = sampling_time\n",
    "        self.outcome = 0\n",
    "\n",
    "    def update_outcome(self, observation, action):\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "        self.outcome += ... ### old += new * sampling_time\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c68ec2",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 4: REINFORCE</h2>\n",
    "\n",
    "***\n",
    "\n",
    "* Actor stores gradients in `self.actor.gradients`\n",
    "* total episodic outcome can be accessed through `self.critic.outcome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicScenarioStudent(EpisodicScenario):\n",
    "\n",
    "    def store_REINFORCE_objective_gradient(self):\n",
    "        \"\"\"\n",
    "        This method should compute and then append reinforce objective gradient \n",
    "        to the `self.episode_REINFORCE_objective_gradients` variable\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "\n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4bf4b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 5: Testing</h2>\n",
    "\n",
    "***\n",
    "\n",
    "Here you have a full freedom of choice: you can tune whatever you want, change whatever you want. Your goal here is to beat a baseline. If you get an outcome g.t. -350, you earn 100 points. If your result lower than -700, you earn nothing.\n",
    "Play with hyperparameters, choose number of episodes and number of iterations. You may also vary the length of one episode. There is plenty of work. Applying is not that straightforward, we made some necessary stuff but your main objective here is to apply your ML an mathematical intuition to obtain the best result you can. You will definitely have some questions. So do not hesitate to DM me on telegram ðŸ˜Š -> @odinmaniac\n",
    "\n",
    "Some addendums:\n",
    "* The problem is pretty stochastic, so sometimes you can occasionally obtain some good results. But the point here is to achieve a convergence! So, if you didn't obtain a stabilization of parameters and loss, it doesn't count (you will be able to see it on 3-rd and 4-th subplot). So, if you think that you obtained some solid results, make plots please, or ask me to launch your notebook if you struggle with hardware or software issues\n",
    "* If you're desperate, results are bad and you don't know what to do, you could try the following heuristics:\n",
    "    * disable the optimization of parameter I (the second one - $\\theta_2$)\n",
    "    * Change learning rate (sometimes you need to change is really drammatically, so it's okay)\n",
    "    * Bound your weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 1 |    7.929 |         3.088 |              -0.106 |     0.814 |             -96.052 |  -741.883 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 1 |    8.429 |         3.092 |               0.086 |     0.192 |             -95.681 |  -789.722 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 1 |    8.929 |         3.136 |               0.019 |     0.335 |             -98.455 |  -838.557 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 1 |    9.429 |         3.146 |              -0.073 |    -0.530 |             -99.291 |  -888.116 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 1 |    9.929 |         3.118 |              -0.012 |    -0.265 |             -97.286 |  -937.129 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    0.419 |         3.108 |              -0.026 |    -0.277 |             -96.672 |  -985.653 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    0.919 |         3.189 |               0.077 |     0.107 |            -101.726 |   -42.146 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    1.419 |         3.172 |              -0.095 |    -0.265 |            -100.722 |   -93.015 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    1.919 |         3.072 |              -0.300 |     0.683 |             -95.084 |  -142.262 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    2.419 |         3.092 |               0.298 |     1.539 |             -98.244 |  -189.180 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    2.919 |         3.298 |               0.117 |    -0.803 |            -109.445 |  -241.211 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    3.419 |         3.145 |              -0.620 |    -0.541 |            -100.356 |  -294.433 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    3.919 |         2.964 |               0.106 |     0.740 |             -88.445 |  -340.475 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    4.419 |         3.190 |               0.619 |    -0.519 |            -103.152 |  -387.697 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    4.919 |         3.303 |              -0.224 |     0.463 |            -109.474 |  -441.974 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    5.419 |         3.090 |              -0.538 |    -0.244 |             -96.439 |  -493.989 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    5.919 |         2.941 |               0.071 |    -0.415 |             -86.699 |  -538.866 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    6.419 |         3.156 |               0.559 |    -0.288 |            -100.654 |  -585.125 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    6.919 |         3.325 |              -0.052 |     0.050 |            -110.567 |  -638.822 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    7.419 |         3.117 |              -0.611 |     0.285 |             -98.367 |  -691.932 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    7.919 |         2.901 |              -0.083 |     0.130 |             -84.216 |  -737.079 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    8.419 |         3.100 |               0.667 |    -0.033 |             -97.445 |  -781.651 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    8.919 |         3.323 |               0.044 |    -0.192 |            -110.438 |  -834.590 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    9.419 |         3.164 |              -0.563 |    -0.565 |            -101.384 |  -888.238 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   1 |                 2 |    9.919 |         2.957 |              -0.170 |     0.289 |             -87.594 |  -935.035 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    0.408 |         3.091 |               0.563 |     0.043 |             -96.492 |  -980.068 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    0.908 |         3.185 |               0.113 |    -0.206 |            -101.552 |   -40.911 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    1.408 |         3.162 |              -0.170 |     0.145 |            -100.070 |   -91.679 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    1.908 |         3.131 |               0.059 |     0.601 |             -98.396 |  -141.016 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    2.408 |         3.104 |              -0.156 |    -0.176 |             -96.436 |  -190.212 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    2.908 |         3.119 |               0.189 |     0.415 |             -97.559 |  -238.230 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    3.407 |         3.179 |              -0.003 |     0.572 |            -101.404 |  -288.303 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    3.907 |         3.166 |              -0.016 |     1.135 |            -101.554 |  -338.824 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    4.407 |         3.154 |              -0.125 |     0.415 |             -99.717 |  -389.041 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    4.907 |         3.100 |              -0.061 |     0.239 |             -96.175 |  -437.960 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    5.407 |         3.139 |               0.123 |    -0.489 |             -98.822 |  -486.426 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    5.907 |         3.168 |               0.008 |    -0.461 |            -100.603 |  -536.317 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    6.407 |         3.186 |               0.078 |    -0.387 |            -101.681 |  -586.842 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    6.907 |         3.127 |              -0.137 |     0.327 |             -97.972 |  -637.249 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    7.407 |         3.104 |               0.133 |     0.065 |             -96.390 |  -685.685 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    7.907 |         3.201 |               0.183 |     0.112 |            -102.565 |  -735.391 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    8.407 |         3.223 |               0.010 |     0.797 |            -104.527 |  -787.387 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    8.907 |         3.138 |              -0.299 |     0.547 |             -99.049 |  -838.597 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    9.407 |         3.055 |               0.017 |    -0.213 |             -93.387 |  -886.338 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n",
      "|   iterations_passed |   episodes_passed |    t [s] |   angle [rad] |   angle_dot [rad/s] |   M [N m] |   running_objective |   outcome |\n",
      "+=====================+===================+==========+===============+=====================+===========+=====================+===========+\n",
      "|                   2 |                 0 |    9.907 |         3.112 |               0.231 |    -0.645 |             -97.392 |  -933.781 |\n",
      "+---------------------+-------------------+----------+---------------+---------------------+-----------+---------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "class PipelineInvertedPendulumStudent(PipelineInvertedPendulum):\n",
    "\n",
    "    def initialize_system(self):\n",
    "        self.system = SysInvertedPendulumStudent(\n",
    "            sys_type=\"diff_eqn\",\n",
    "            dim_state=self.dim_state,\n",
    "            dim_input=self.dim_input,\n",
    "            dim_output=self.dim_output,\n",
    "            dim_disturb=self.dim_disturb,\n",
    "            pars=[self.m, self.g, self.l],\n",
    "            is_dynamic_controller=self.is_dynamic_controller,\n",
    "            is_disturb=self.is_disturb,\n",
    "            pars_disturb=[],\n",
    "        )\n",
    "        self.observation_init = self.system.out(self.state_init, time=0)\n",
    "\n",
    "    def initialize_models(self):\n",
    "        super().initialize_models()\n",
    "        self.actor_model = ModelGaussianConditionalStudent(\n",
    "            expectation_function=self.safe_controller,\n",
    "            arg_condition=self.observation_init,\n",
    "            weights=self.initial_weights,\n",
    "        )\n",
    "\n",
    "    def initialize_actor_critic(self):\n",
    "        self.critic = CriticTrivialStudent(\n",
    "            running_objective=self.running_objective, sampling_time=self.sampling_time\n",
    "        )\n",
    "        self.actor = ActorProbabilisticEpisodicStudent(\n",
    "            self.prediction_horizon,\n",
    "            self.dim_input,\n",
    "            self.dim_output,\n",
    "            self.control_mode,\n",
    "            self.action_bounds,\n",
    "            action_init=self.action_init,\n",
    "            predictor=self.predictor,\n",
    "            optimizer=self.actor_optimizer,\n",
    "            critic=self.critic,\n",
    "            running_objective=self.running_objective,\n",
    "            model=self.actor_model,\n",
    "        )\n",
    "\n",
    "    def initialize_scenario(self):\n",
    "        self.scenario = EpisodicScenarioStudent(\n",
    "            system=self.system,\n",
    "            simulator=self.simulator,\n",
    "            controller=self.controller,\n",
    "            actor=self.actor,\n",
    "            critic=self.critic,\n",
    "            logger=self.logger,\n",
    "            datafiles=self.datafiles,\n",
    "            time_final=self.time_final,\n",
    "            running_objective=self.running_objective,\n",
    "            no_print=self.no_print,\n",
    "            is_log=self.is_log,\n",
    "            is_playback=self.is_playback,\n",
    "            N_episodes=self.N_episodes,\n",
    "            N_iterations=self.N_iterations,\n",
    "            state_init=self.state_init,\n",
    "            action_init=self.action_init,\n",
    "        )\n",
    "\n",
    "    def execute_pipeline(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Full execution routine\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        self.load_config()\n",
    "        self.setup_env()\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.initialize_system()\n",
    "        self.initialize_predictor()\n",
    "        self.initialize_safe_controller()\n",
    "        self.initialize_models()\n",
    "        self.initialize_objectives()\n",
    "        self.initialize_optimizers()\n",
    "        self.initialize_actor_critic()\n",
    "        self.initialize_controller()\n",
    "        self.initialize_simulator()\n",
    "        self.initialize_logger()\n",
    "        self.initialize_scenario()\n",
    "        if not self.no_visual and not self.save_trajectory:\n",
    "            self.initialize_visualizer()\n",
    "            self.main_loop_visual()\n",
    "        else:\n",
    "            self.scenario.run()\n",
    "            if self.is_playback:\n",
    "                self.playback()\n",
    "                \n",
    "    #def playback(self):\n",
    "    #    self.initialize_visualizer()\n",
    "    #    anm = animation.FuncAnimation(\n",
    "    #        self.animator.fig_sim,\n",
    "    #        self.animator.playback,\n",
    "    #        init_func=self.animator.init_anim,\n",
    "    #        blit=False,\n",
    "    #        interval=self.sampling_time / 1e6,\n",
    "    #        repeat=False,\n",
    "    #    )\n",
    "#\n",
    "    #    self.animator.get_anm(anm)\n",
    "    #    self.animator.speedup = self.speedup\n",
    "#\n",
    "    #    cId = self.animator.fig_sim.canvas.mpl_connect(\n",
    "    #        \"key_press_event\", lambda event: on_key_press(event, anm)\n",
    "    #    )\n",
    "#\n",
    "    #    anm.running = True\n",
    "#\n",
    "    #    self.animator.fig_sim.tight_layout()\n",
    "    #    plt.show()\n",
    "    \n",
    "##### Execution here!!! Full list of kwargs can be seen at \n",
    "##### rcognita_framework.pipelines.config_blueprints in the ConfigInvertedPendulum\n",
    "pipeline = PipelineInvertedPendulumStudent()\n",
    "pipeline.execute_pipeline(\n",
    "    no_visual=True, \n",
    "    time_final=10, \n",
    "    speedup=50,\n",
    "    is_playback=True, \n",
    "    N_episodes=3, \n",
    "    N_iterations=8, \n",
    "    learning_rate=0.01,\n",
    "    initial_weights=[1., 0., 1.],\n",
    "    sampling_time=0.1, # Do not change it!\n",
    "    no_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6317032",
   "metadata": {},
   "source": [
    "### Grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineInvertedPendulumStudent()\n",
    "pipeline.execute_pipeline(\n",
    "    no_visual=True, \n",
    "    t1=10, \n",
    "    is_playback=False, \n",
    "    N_episodes= , ##### set your episodes number \n",
    "    N_iterations=1,##### set your iterations number \n",
    "    initial_weights=[1., 0., 1.],\n",
    "    no_print=True)\n",
    "\n",
    "mean_episodic = pipeline.scenario.outcome_episodic_means[0]\n",
    "grade = np.clip(0.28 * mean_episodic + 200, 0, 100)\n",
    "print(f\"Your grade: {grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6246a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_episodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73868a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
